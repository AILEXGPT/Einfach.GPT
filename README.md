# üîí Einfach.PGPT üìë

> Installations- und Nutzungsdokumentation: https://docs.privategpt.dev/

Einfach.PGPT ist ein produktionsbereites KI-Projekt, das es dir erm√∂glicht, Fragen zu deinen Dokumenten mithilfe der Kraft von Gro√üen Sprachmodellen (LLMs) zu stellen, auch in Szenarien ohne Internetverbindung. 100% privat, keine Daten verlassen deine Ausf√ºhrungsumgebung zu irgendeinem Zeitpunkt.

Das Projekt bietet eine API, die alle Grundlagen bietet, um private, kontextbewusste KI-Anwendungen zu erstellen. Es folgt und erweitert den [OpenAI API-Standard](https://openai.com/blog/openai-api) und unterst√ºtzt sowohl normale als auch Streaming-Antworten.

Die API ist in zwei logische Bl√∂cke unterteilt:

**High-Level-API**, die die gesamte Komplexit√§t einer RAG (Retrieval Augmented Generation) Pipeline-Implementierung abstrahiert:
- Einlesen von Dokumenten: internes Verwalten von Dokumenten-Parsing, Aufteilung, Metadatenextraktion, Erzeugung von Einbettungen und Speicherung.
- Chat & Vervollst√§ndigungen unter Verwendung von Kontext aus eingelesenen Dokumenten: Abstraktion der Kontexterfassung, der Prompt-Engineering und der Antwortgenerierung.

**Low-Level-API**, die es fortgeschrittenen Benutzern erm√∂glicht, ihre eigenen komplexen Pipelines zu implementieren:
- Erzeugung von Einbettungen: basierend auf einem Textst√ºck.
- Kontextbezogene Chunks-Abruf: Bei einer Anfrage werden die relevantesten Textabschnitte aus den eingelesenen Dokumenten zur√ºckgegeben.

Zus√§tzlich dazu wird ein funktionierender [Gradio UI](https://www.gradio.app/) Client bereitgestellt, um die API zu testen, zusammen mit einer Reihe n√ºtzlicher Tools wie Bulk-Model-Download-Skript, Einleseskript, Dokumentenordner-√úberwachung usw.

> üëÇ **Brauchst du Hilfe bei der Anwendung von Einfach.PGPT f√ºr deinen spezifischen Anwendungsfall?**
> [Lass es uns wissen](https://forms.gle/4cSDmH13RZBHV9at7) und wir werden versuchen zu helfen! Wir verfeinern Einfach.PGPT durch dein Feedback.

## üéûÔ∏è √úberblick
HAFTUNGSAUSSCHLUSS: Diese README wird nicht so h√§ufig aktualisiert wie die [Dokumentation](https://docs.privategpt.dev/). Bitte schaue dort nach den neuesten Updates!

### Motivation hinter Einfach.PGPT
Generative KI ist ein Game-Changer f√ºr unsere Gesellschaft, aber die Einf√ºhrung in Unternehmen aller Gr√∂√üen und datensensiblen Bereichen wie Gesundheitswesen oder Recht ist durch eine klare Sorge begrenzt: **Privatsph√§re**. Nicht sicherstellen zu k√∂nnen, dass deine Daten vollst√§ndig unter deiner Kontrolle sind, wenn du KI-Tools von Drittanbietern verwendest, ist ein Risiko, das diese Branchen nicht eingehen k√∂nnen.

### Urversion
Die erste Version von Einfach.PGPT wurde im Mai 2023 als neuartiger Ansatz eingef√ºhrt, um die Datenschutzbedenken anzugehen, indem LLMs auf eine vollst√§ndig offline Weise verwendet wurden. Dies wurde durch die Nutzung bestehender Technologien erreicht, die von der florierenden Open-Source-KI-Gemeinschaft entwickelt wurden: [LangChain](https://github.com/hwchase17/langchain), [LlamaIndex](https://www.llamaindex.ai/), [GPT4All](https://github.com/nomic-ai/gpt4all), [LlamaCpp](https://github.com/ggerganov/llama.cpp), [Chroma](https://www.trychroma.com/) und [SentenceTransformers](https://www.sbert.net/).

Diese Version, die schnell zu einem Go-to-Projekt f√ºr datenschutzsensible Setups wurde und als Grundlage f√ºr Tausende von lokal fokussierten generativen KI-Projekten diente, war der Grundstein dessen, was Einfach.PGPT heutzutage wird; also eine einfachere und lehrreichere Implementierung, um die grundlegenden Konzepte zu verstehen, die erforderlich sind, um ein vollst√§ndig lokales - und daher privates - ChatGPT-√§hnliches Tool zu erstellen.

Wenn du weiterhin damit experimentieren m√∂chtest, haben wir es im [primordial branch](https://github.com/imartinez/privateGPT/tree/primordial) des Projekts gespeichert.

> Es wird dringend empfohlen, eine saubere Klonung und Installation dieser neuen Version von Einfach.PGPT durchzuf√ºhren, wenn du von der vorherigen, urzeitlichen Version kommst.

### Gegenwart und Zukunft von Einfach.PGPT
Einfach.PGPT entwickelt sich nun zu einem Gateway f√ºr generative KI-Modelle und Grundbausteine, einschlie√ülich Vervollst√§ndigungen, Dokumenteneinlesung, RAG-Pipelines und anderen Low-Level-Bausteinen. Wir m√∂chten es jedem Entwickler erleichtern, KI-Anwendungen und -Erfahrungen zu erstellen, sowie eine geeignete umfangreiche Architektur f√ºr die Community bereitstellen, um weiter beizutragen.

Bleibe auf dem Laufenden mit unseren [Ver√∂ffentlichungen](https://github.com/imartinez/privateGPT/releases), um alle neuen Funktionen und √Ñnderungen zu sehen.

## üìÑ Dokumentation
Die vollst√§ndige Dokumentation zu Installation, Abh√§ngigkeiten, Konfiguration, Serverbetrieb, Bereitstellungsoptionen, Einlesen lokaler Dokumente, API-Details und UI-Funktionen findest du hier: https://docs.privategpt.dev/

## üß© Architektur
Konzeptionell ist Einfach.PGPT eine API, die eine RAG-Pipeline umschlie√üt und deren Grundbausteine freilegt.
* Die API wurde mit [FastAPI](https://fastapi.tiangolo.com/) erstellt und folgt dem [API-Schema von OpenAI](https://platform.openai.com/docs/api-reference).
* Die RAG-Pipeline basiert auf [LlamaIndex](https://www.llamaindex.ai/).

Das Design von Einfach.PGPT erm√∂glicht es, sowohl die API als auch die RAG-Implementierung leicht zu erweitern und anzupassen. Einige wichtige architektonische Entscheidungen sind:
* Dependency Injection, Entkopplung der verschiedenen Komponenten und Schichten.
* Verwendung von LlamaIndex-Abstraktionen wie `LLM`, `BaseEmbedding` oder `VectorStore`, was es sofort erm√∂glicht, die tats√§chlichen Implementierungen dieser Abstraktionen zu √§ndern.
* Einfachheit, so wenige Schichten und neue Abstraktionen wie m√∂glich hinzuzuf√ºgen.
* Einsatzbereit, Bereitstellung einer vollst√§ndigen Implementierung der API und RAG-Pipeline.

Hauptbausteine:
* APIs sind in `private_gpt:server:<api>` definiert. Jedes Paket enth√§lt eine `<api>_router.py` (FastAPI-Schicht) und eine `<api>_service.py` (die Service-Implementierung). Jeder *Service* verwendet LlamaIndex-Basisabstraktionen anstelle von spezifischen Implementierungen, wodurch die tats√§chliche Implementierung von ihrer Nutzung entkoppelt wird.
* Komponenten befinden sich in `private_gpt:components:<component>`. Jede *Komponente* ist daf√ºr verantwortlich, tats√§chliche Implementierungen f√ºr die Basisabstraktionen bereitzustellen, die in den Services verwendet werden - zum Beispiel ist `LLMComponent` daf√ºr verantwortlich, eine tats√§chliche Implementierung eines `LLM` bereitzustellen (zum Beispiel `LlamaCPP` oder `OpenAI`).

## üí° Mitwirken
Beitr√§ge sind willkommen! Um die Codequalit√§t zu gew√§hrleisten, haben wir mehrere Format- und Typisierungspr√ºfungen aktiviert, f√ºhre einfach `make check` vor dem Commit durch, um sicherzustellen, dass dein Code in Ordnung ist. Denke daran, deinen Code zu testen! Du findest einen Testordner mit Hilfsmitteln, und du kannst Tests mit dem Befehl `make test` ausf√ºhren.

Interessiert daran, zu Einfach.PGPT beizutragen? Wir haben die folgenden Herausforderungen vor uns, falls du helfen m√∂chtest:

### Verbesserungen
- Bessere RAG-Pipeline-Implementierung (Verbesserungen sowohl in den Indexierungs- als auch in den Abfragephasen)
- Code-Dokumentation
- Exposition von Ausf√ºhrungsparametern wie top_p, Temperatur, max_tokens... in Vervollst√§ndigungen und Chat-Vervollst√§ndigungen
- Exposition der Chunk-Gr√∂√üe in der Ingest-API
- Implementierung von Update und Delete-Dokument in der Ingest-API
- Hinzuf√ºgen von Informationen √ºber den Tokenverbrauch in jeder Antwort
- Hinzuf√ºgen zu den Vervollst√§ndigungs-APIs (Chat und Vervollst√§ndigung) der Kontextdokumente, die zur Beantwortung der Frage verwendet wurden
- Im "Modell"-Feld den tats√§chlichen Namen des LLM- oder Einbettungsmodells zur√ºckgeben

### Funktionen
- Implementierung eines Concurrency-Locks, um Fehler zu vermeiden, wenn es mehrere Aufrufe des lokalen LlamaCPP-Modells gibt
- API-Schl√ºssel-basierte Anforderungskontrolle zur API
- Unterst√ºtzung f√ºr Sagemaker
- Unterst√ºtzung von Funktionsaufrufen
- Hinzuf√ºgen von md5, um bereits eingelesene Dateien zu √ºberpr√ºfen
- Auswahl eines Dokuments zur Abfrage in der UI
- Bessere Beobachtbarkeit der RAG-Pipeline

### Projektinfrastruktur
- Verpackte Version als lokale Desktop-App (Windows-Exe, Mac-App, Linux-App)
- Dockerisierung der Anwendung f√ºr Plattformen au√üerhalb von Linux (Docker Desktop f√ºr Mac und Windows)
- Dokumentation, wie man auf AWS, GCP und Azure bereitstellt.

##

## üí¨ Community
Tritt der Diskussion um Einfach.PGPT auf unseren Plattformen bei:
- [Twitter (aka X)](https://twitter.com/PrivateGPT_AI)
- [Discord](https://discord.gg/bK6mRVpErU)

## üìñ Zitation
Wenn du Einfach.PGPT in einer Publikation verwendest, schau dir die [Zitationsdatei](CITATION.cff) f√ºr die korrekte Zitation an.  
Du kannst auch den Button "Dieses Repository zitieren" in diesem Repo verwenden, um die Zitation in verschiedenen Formaten zu erhalten.

Hier sind ein paar Beispiele:

#### BibTeX
```bibtex
@software{Martinez_Toro_PrivateGPT_2023,
author = {Mart√≠nez Toro, Iv√°n and Gallego Vico, Daniel and Orgaz, Pablo},
license = {Apache-2.0},
month = may,
title = {{Einfach.PGPT}},
url = {https://github.com/imartinez/privateGPT},
year = {2023}
}


#### APA
```
Mart√≠nez Toro, I., Gallego Vico, D., & Orgaz, P. (2023). PrivateGPT [Computer software]. https://github.com/imartinez/privateGPT
```
